{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MigKA4SROApl"
      },
      "source": [
        "#**DISEASES PREDICTION FROM MEDICAL DATA : BREAST CANCER PREDICTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db2tFHTnOHob"
      },
      "source": [
        "**IMPORT LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N4hkQsuc5c6"
      },
      "outputs": [],
      "source": [
        "# 1. Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO9HrBNrOcsn"
      },
      "source": [
        "**LOAD THE DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ca19LDEObLM"
      },
      "outputs": [],
      "source": [
        "# 2. Load dataset\n",
        "df = pd.read_csv(\"/content/Breast Cancer.csv\")\n",
        "\n",
        "# Show first few rows\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK7hUJoCPOnZ"
      },
      "source": [
        "**DATA PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXWCx_NVOUPY"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=[\"radius_mean\"])\n",
        "\n",
        "# Encode target column 'diagnosis' (M=1, B=0)\n",
        "# le = LabelEncoder()\n",
        "# df[\"diagnosis\"] = le.fit_transform(df[\"diagnosis\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYJ5bUQ8Pcy5"
      },
      "outputs": [],
      "source": [
        "# Split features & target\n",
        "X = df.drop(columns=[\"compactness_mean\"])\n",
        "y = df[\"compactness_mean\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1203qBNTPgaX"
      },
      "outputs": [],
      "source": [
        "#  Check missing values\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
        "\n",
        "#  Encode categorical columns if any\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccgho1nkPmGn"
      },
      "outputs": [],
      "source": [
        "# 5. Split into features & target\n",
        "X = df.drop(columns=[\"diagnosis\", \"Unnamed: 32\", \"id\"])\n",
        "y = df[\"diagnosis\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leKPMgmiPsEL"
      },
      "outputs": [],
      "source": [
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9RT4SfhPvKi"
      },
      "outputs": [],
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Features shape:\", X_scaled.shape)\n",
        "print(\"Target distribution:\\n\", y.value_counts())\n",
        "\n",
        "# Save the scaler\n",
        "import joblib\n",
        "joblib.dump(scaler, \"scaler.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmLeJgzqQTPm"
      },
      "source": [
        "**SPLIT THE DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NSB918sQQh9"
      },
      "outputs": [],
      "source": [
        "# Split into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2HxMLVTgYCr"
      },
      "source": [
        "**TRAIN WITH DIFFERENT MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hLQn6CmgR1Y"
      },
      "outputs": [],
      "source": [
        "# Train Logistic Regression\n",
        "log_model = LogisticRegression(max_iter=1000, solver='liblinear')\n",
        "log_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_prd_log = log_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcw2cVcehwej"
      },
      "outputs": [],
      "source": [
        "# 8. Train Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQKhxLn2igYW"
      },
      "outputs": [],
      "source": [
        "# 9. Train Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQRm1L2djD6G"
      },
      "outputs": [],
      "source": [
        "# 10. Train Support Vector Machine (SVM)\n",
        "from sklearn.svm import SVC\n",
        "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1baoR4uRolT6"
      },
      "outputs": [],
      "source": [
        "# 11. Train Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "y_pred_nb = nb_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model (no use_label_encoder)\n",
        "xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZxkyGknEZcJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# y_test : true values\n",
        "# y_prd_log : predictions from logistic regression\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_prd_log)\n",
        "mse = mean_squared_error(y_test, y_prd_log)\n",
        "r2 = r2_score(y_test, y_prd_log)\n",
        "\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R² Score:\", r2)\n"
      ],
      "metadata": {
        "id": "7OWRFio4ZYn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Fi6R4zWmLn4"
      },
      "outputs": [],
      "source": [
        "# Include all models\n",
        "models = {\n",
        "    \"Logistic Regression\": (log_model, y_prd_log),\n",
        "    \"Random Forest\": (rf_model, y_pred_rf),\n",
        "    \"Decision Tree\": (dt_model, y_pred_dt),\n",
        "    \"SVM\": (svm_model, y_pred_svm),\n",
        "    \"Naive Bayes\": (nb_model, y_pred_nb),\n",
        "    \"XGBoost\": (xgb_model, y_pred_xgb)   # ✅ Added XGBoost\n",
        "}\n",
        "\n",
        "# Loop through and evaluate\n",
        "for name, (model, y_pred) in models.items():\n",
        "    print(f\"\\n{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))  # Avoid warnings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XezcE9Afr3p_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Include all models\n",
        "models = {\n",
        "    \"Logistic Regression\": (log_model, y_prd_log),\n",
        "    \"Random Forest\": (rf_model, y_pred_rf),\n",
        "    \"Decision Tree\": (dt_model, y_pred_dt),\n",
        "    \"SVM\": (svm_model, y_pred_svm),\n",
        "    \"Naive Bayes\": (nb_model, y_pred_nb),\n",
        "    \"XGBoost\": (xgb_model, y_pred_xgb)   # ✅ Added XGBoost\n",
        "}\n",
        "\n",
        "for name, (model, y_pred) in models.items():\n",
        "    print(f\"\\n{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'{name} Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij-dpaiL43Yx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Dictionary of models\n",
        "models = {\n",
        "    \"Logistic Regression\": (log_model, y_prd_log),\n",
        "    \"Random Forest\": (rf_model, y_pred_rf),\n",
        "    \"Decision Tree\": (dt_model, y_pred_dt),\n",
        "    \"SVM\": (svm_model, y_pred_svm),\n",
        "    \"Naive Bayes\": (nb_model, y_pred_nb),\n",
        "    \"XGBoost\": (xgb_model, y_pred_xgb)   # ✅ Added XGBoost\n",
        "}\n",
        "# Collect accuracies\n",
        "model_names = []\n",
        "accuracies = []\n",
        "\n",
        "for name, (model, y_pred) in models.items():\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    model_names.append(name)\n",
        "    accuracies.append(acc)\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Plot bar graph\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(model_names, accuracies, color='skyblue')\n",
        "plt.ylim(0, 1)  # Accuracy between 0 and 1\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracies Comparison')\n",
        "for i, v in enumerate(accuracies):\n",
        "    plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center')  # Show accuracy on top of bar\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12RlOJDWymHV"
      },
      "source": [
        "**VISUALIZE THROUGH GRAPHS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ppHa_UV1Ljp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/Breast Cancer.csv')\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_cols = df.select_dtypes(include=['object', 'category', 'int']).columns\n",
        "\n",
        "print(\"Numerical columns:\", num_cols)\n",
        "print(\"Categorical columns:\", cat_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5oJEvIJ13JM"
      },
      "source": [
        "**1. Numerical Columns – Histogram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBMO7mNr1x9S"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Exclude 'id' and 'Unnamed: 32' from the numerical columns for plotting\n",
        "num_cols_to_plot = [col for col in num_cols if col not in ['id', 'Unnamed: 32']]\n",
        "\n",
        "for col in num_cols_to_plot:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.histplot(df[col], bins=20, kde=False, color='skyblue')\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcCabki82dW4"
      },
      "source": [
        "**2. Numerical Columns – Boxplot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZz7TUgRAWov"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Select a few features to visualize\n",
        "features_to_plot = [\"radius_mean\", \"texture_mean\", \"area_mean\", \"smoothness_mean\"]\n",
        "\n",
        "# Create boxplots\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i, feature in enumerate(features_to_plot, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.boxplot(x=\"diagnosis\", y=feature, hue=\"diagnosis\", data=df, palette=\"Set2\", legend=False)\n",
        "    plt.title(f\"Boxplot of {feature} by Diagnosis\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na_Wwgre3wAD"
      },
      "source": [
        "**3 . Categorical Columns – Pie Chart**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhdy2bggAUNu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count values of diagnosis\n",
        "diagnosis_counts = df[\"diagnosis\"].value_counts()\n",
        "\n",
        "# Pie chart\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(\n",
        "    diagnosis_counts,\n",
        "    labels=[\"Benign (0)\", \"Malignant (1)\"],\n",
        "    autopct=\"%1.1f%%\",\n",
        "    startangle=90,\n",
        "    colors=[\"#66b3ff\", \"#ff9999\"]\n",
        ")\n",
        "plt.title(\"Distribution of Diagnosis (Benign vs Malignant)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIbqJ0Gr3ok0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Select only numeric columns\n",
        "num_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
        "\n",
        "# Encode diagnosis column to numeric for correlation calculation\n",
        "le = LabelEncoder()\n",
        "df['diagnosis_encoded'] = le.fit_transform(df['diagnosis'])\n",
        "\n",
        "# Compute correlation matrix including the encoded diagnosis column\n",
        "corr = df[num_cols.tolist() + ['diagnosis_encoded']].corr()\n",
        "\n",
        "# Select top 10 features most correlated with diagnosis\n",
        "top_features = corr[\"diagnosis_encoded\"].abs().sort_values(ascending=False).head(11).index  # 11 because it includes 'diagnosis_encoded'\n",
        "\n",
        "# Subset correlation matrix for these features\n",
        "top_corr = df[top_features].corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(top_corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Top 10 Features Correlated with Diagnosis\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Y-DATA REPORT OR PROFILLING**"
      ],
      "metadata": {
        "id": "0EjBHrV8bMkK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHBLO1FpDpTj"
      },
      "outputs": [],
      "source": [
        "# Install if not already installed\n",
        "!pip install ydata-profiling\n",
        "\n",
        "import pandas as pd\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sz5eh8XD2Ws"
      },
      "outputs": [],
      "source": [
        "# Generate profiling report\n",
        "profile = ProfileReport(df, title=\"Breast Cancer Dataset Profiling Report\", explorative=True)\n",
        "\n",
        "# Save to HTML\n",
        "profile.to_file(\"profiling_report.html\")\n",
        "\n",
        "# Or display directly in Jupyter Notebook\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PREDICTIONS**"
      ],
      "metadata": {
        "id": "oJRIMnNPbVHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Logistic Regression predictions\n",
        "y_pred_log = log_model.predict(X_test)\n",
        "\n",
        "pred_df = pd.DataFrame({\n",
        "    \"Actual\": y_test,\n",
        "    \"Predicted (Logistic Regression)\": y_pred_log\n",
        "})\n",
        "\n",
        "print(pred_df.head(10))\n"
      ],
      "metadata": {
        "id": "xgStcmpUbpoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction probabilities for all models\n",
        "pred_proba_df = pd.DataFrame({\n",
        "    \"Actual\": y_test.reset_index(drop=True),\n",
        "    \"Logistic Regression\": log_model.predict_proba(X_test)[:,1],\n",
        "    \"Random Forest\": rf_model.predict_proba(X_test)[:,1],\n",
        "    \"Decision Tree\": dt_model.predict_proba(X_test)[:,1],\n",
        "    \"SVM\": svm_model.predict_proba(X_test)[:,1],\n",
        "    \"Naive Bayes\": nb_model.predict_proba(X_test)[:,1],\n",
        "    \"XGBoost\": xgb_model.predict_proba(X_test)[:,1],\n",
        "})\n",
        "\n",
        "print(pred_proba_df.head(10))\n"
      ],
      "metadata": {
        "id": "8e51L-3TcnEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_predictions(y_test, y_pred, model_name, n=50):\n",
        "    \"\"\"\n",
        "    Plot actual vs predicted values for a given model.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(y_test.values[:n], label=\"Actual\", marker=\"o\")\n",
        "    plt.plot(y_pred[:n], label=\"Predicted\", marker=\"x\")\n",
        "    plt.title(f\"{model_name} Predictions vs Actual\")\n",
        "    plt.xlabel(\"Sample Index\")\n",
        "    plt.ylabel(\"Class (0=Benign, 1=Malignant)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_predictions(y_test, y_prd_log, \"Logistic Regression\")\n",
        "plot_predictions(y_test, y_pred_rf, \"Random Forest\")\n",
        "plot_predictions(y_test, y_pred_dt, \"Decision Tree\")\n",
        "plot_predictions(y_test, y_pred_svm, \"SVM\")\n",
        "plot_predictions(y_test, y_pred_nb, \"Naive Bayes\")\n",
        "plot_predictions(y_test, y_pred_xgb, \"XGBoost\")\n"
      ],
      "metadata": {
        "id": "ioL2nGBwctqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsYE8kE_dpiq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}